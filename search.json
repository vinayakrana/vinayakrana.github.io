[
  {
    "objectID": "tech_nuggets/index.html",
    "href": "tech_nuggets/index.html",
    "title": "Tech Nuggets",
    "section": "",
    "text": "Understanding the ‚Äúwhy‚Äù behind system behavior is a core skill in software and ML engineering. These posts demonstrate a habit of going deep into how things work, whether that‚Äôs a faster dictionary lookup, how PyTorch builds a dynamic computation graph, or what causes a memory spike in Docker containers."
  },
  {
    "objectID": "tech_nuggets/index.html#latest-posts",
    "href": "tech_nuggets/index.html#latest-posts",
    "title": "Tech Nuggets",
    "section": "Latest Posts",
    "text": "Latest Posts"
  },
  {
    "objectID": "tech_nuggets/posts/dict_key_lookup.html",
    "href": "tech_nuggets/posts/dict_key_lookup.html",
    "title": "Dict Lookup",
    "section": "",
    "text": "In Python, checking whether a key exists in a dictionary is a common operation. But there‚Äôs more than one way to write it:\nif key in my_dict: ...\nif key in my_dict.keys(): ...\nAt first glance, both seem correct and equivalent. But they are not equal in performance or clarity.\nIn this post, we‚Äôll dive into:\n\nThe internal differences between the two\nThe disassembled bytecode\nReal-world benchmarks using timeit\nBest practices and when it actually matters\n\nLet‚Äôs compare the bytecode of two functions, one using in dict and the other using in dict.keys() to see what Python does under the hood.\n\nimport dis\n\ndef direct_lookup(hmap, x):\n    return x in hmap\n\ndef keys_lookup(hmap, x):\n    return x in hmap.keys()\n\ndis.dis(direct_lookup)\nprint(\"-\" * 40)\ndis.dis(keys_lookup)\n\n  4           0 LOAD_FAST                1 (x)\n              2 LOAD_FAST                0 (hmap)\n              4 CONTAINS_OP              0\n              6 RETURN_VALUE\n----------------------------------------\n  7           0 LOAD_FAST                1 (x)\n              2 LOAD_FAST                0 (hmap)\n              4 LOAD_METHOD              0 (keys)\n              6 CALL_METHOD              0\n              8 CONTAINS_OP              0\n             10 RETURN_VALUE\n\n\n\nx in hmap\n\nDirectly uses COMPARE_OP with in on the dictionary\nCalls dict.__contains__, which is optimized and fast\n\n\n\nx in hmap.keys()\n\nCalls .keys() ‚Üí creates a dict_keys view object\nPerforms a membership test on the view\n\nThis adds extra function calls and memory allocation, even though the lookup is still O(1).\nLet‚Äôs use timeit to compare the performance of both lookup styles over 100,000 iterations.\n\nimport timeit\n\nsetup = \"hmap = dict(zip(range(10000), range(10000))); x = 9999\"\nstmt1 = \"x in hmap\"\nstmt2 = \"x in hmap.keys()\"\n\ntime_direct = timeit.timeit(stmt1, setup=setup, number=100_000)\ntime_keys = timeit.timeit(stmt2, setup=setup, number=100_000)\n\nprint(f\"'x in hmap'       : {time_direct:.5f} sec\")\nprint(f\"'x in hmap.keys()': {time_keys:.5f} sec\")\n\n'x in hmap'       : 0.00363 sec\n'x in hmap.keys()': 0.00700 sec\n\n\n\n\nSummary\n\n\n\nStyle\nPerformance\nMemory\n\n\n\n\nx in dict\nFast\nLow\n\n\nx in dict.keys()\nSlower\nHigher\n\n\n\n\n\nWhen to Use .keys()\nUse .keys() only when you need to iterate over or manipulate the entire view object ‚Äî not for simple membership tests.\n\n\n\nWhy It Matters\nWhile the difference is small in absolute terms, understanding Python internals helps write clearer and more efficient code. It also prepares you to debug or optimize larger systems more confidently."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vinayak Rana",
    "section": "",
    "text": "Vinayak Rana is a Master‚Äôs student in Artificial Intelligence at IIT Gandhinagar. He is an active member of the Sustainability Lab, advised by Prof.¬†Nipun Batra. His interests lie in building practical and reliable AI systems, with a focus on spatiotemporal modeling, active learning and natural language processing. Vinayak is passionate about applying machine learning techniques to solve real-world problems and is actively exploring opportunities to contribute to impactful AI research and development. He secured an All India Rank (AIR) of 733 in GATE CS 2024."
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Publications",
    "section": "",
    "text": "Coming soon‚Ä¶.."
  },
  {
    "objectID": "papers/index.html#section",
    "href": "papers/index.html#section",
    "title": "Publications",
    "section": "",
    "text": "Coming soon‚Ä¶.."
  },
  {
    "objectID": "timeline.html",
    "href": "timeline.html",
    "title": "Timeline",
    "section": "",
    "text": "Will be updated soon‚Ä¶."
  },
  {
    "objectID": "timeline.html#section",
    "href": "timeline.html#section",
    "title": "Timeline",
    "section": "",
    "text": "Will be updated soon‚Ä¶."
  },
  {
    "objectID": "apps.html",
    "href": "apps.html",
    "title": "ScholarBot: AI-powered chatbot designed to assist with academic queries",
    "section": "",
    "text": "ScholarBot: AI-powered chatbot designed to assist with academic queries"
  },
  {
    "objectID": "tech_nuggets/posts/gumbel.html",
    "href": "tech_nuggets/posts/gumbel.html",
    "title": "Gumbel Softmax trick",
    "section": "",
    "text": "Can You Backprop Through a Discrete Choice?\nSuppose your model must choose one of several categories say, Red, Green, or Blue.\nYou use argmax or sample from a categorical distribution. But then how do you backpropagate?\n\n\nAnswer: You can‚Äôt.\nBut you can cheat slightly and still train using the Gumbel-Softmax trick.\n\n\nThe Problem: argmax Breaks Gradients\nimport torch\nimport torch.nn.functional as F\n\nlogits = torch.tensor([[2.0, 1.0, 0.1]], requires_grad=True)\nprobs = F.softmax(logits, dim=-1)\nsample = torch.argmax(probs, dim=-1)\n\nloss = sample.float().sum()\nloss.backward()  #  Throws an error\n\n\nüßô‚Äç‚ôÇÔ∏è The Magic Behind Gumbel-Softmax\nOkay, you want your model to pick one option out of many. But you still want to train it with backprop?\nMost people try this:\nchoice = torch.argmax(logits, dim=-1)  # ‚ùå Not differentiable\n\nBoom. Backprop dies.\nGradients have no idea how to flow through that hard decision.\nSo what if instead of a hard choice we pretend to choose using a soft, trainable mask?\nThat‚Äôs exactly what the Gumbel-Softmax trick does.\n\nimport torch\nimport torch.nn.functional as F\n\ndef sample_gumbel(shape, eps=1e-20):\n    U = torch.rand(shape)\n    return -torch.log(-torch.log(U + eps) + eps)\n\ndef gumbel_softmax(logits, tau=1.0):\n    g = sample_gumbel(logits.shape)\n    return F.softmax((logits + g) / tau, dim=-1)\n\n\nlogits are your unnormalized preferences\ng is random Gumbel noise added to shake things up\ntau is the temperature, controls how sharp or soft the final decision is\nSoftmax turns the noisy preferences into a smooth probability vector\n\nAs tau ‚Üí 0 The softmax becomes sharper, and the output becomes almost one-hot like a discrete decision!\nVisual Example: Learn to Blend Colors Let‚Äôs say your model needs to pick one color ‚Äî Red, Green, or Blue ‚Äî to match a target color (like purple üíú).\nBut instead of making a hard choice, it learns to blend the colors using Gumbel-Softmax.\n\nimport torch\n# Our palette\npalette = torch.tensor([\n    [1.0, 0.0, 0.0],  # Red\n    [0.0, 1.0, 0.0],  # Green\n    [0.0, 0.0, 1.0]   # Blue\n])\n\n# Trainable selection logits\nlogits = torch.nn.Parameter(torch.randn(1, 3))\n\n# Our target is purple (red + blue)\ntarget = torch.tensor([[0.5, 0.0, 0.5]])\n\nopt = torch.optim.Adam([logits], lr=0.1)\n\n\nlosses = []\n\nfor step in range(100):\n    opt.zero_grad()\n    probs = gumbel_softmax(logits, tau=0.5)\n    color = probs @ palette  # Weighted blend\n    loss = F.mse_loss(color, target)\n    losses.append(loss.item())\n    loss.backward()\n    opt.step()\n\n    if step % 10 == 0:\n        print(f\"Step {step}: Loss = {loss.item():.4f}\")\n\nStep 0: Loss = 0.0150\nStep 10: Loss = 0.1047\nStep 20: Loss = 0.1366\nStep 30: Loss = 0.1662\nStep 40: Loss = 0.1665\nStep 50: Loss = 0.0556\nStep 60: Loss = 0.0257\nStep 70: Loss = 0.1486\nStep 80: Loss = 0.1489\nStep 90: Loss = 0.0219\n\n\n\nimport matplotlib.pyplot as plt\nwith torch.no_grad():\n    probs = F.softmax(logits, dim=-1)\n    blended = probs @ palette\n\n    plt.imshow(blended.view(1, 1, 3).numpy())\n    plt.title(f\"Final Color ‚Äî probs={probs.numpy().round(2)}\")\n    plt.axis('off')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\nBoom! The model learns a soft mix of red and blue to match the purple target.\n\n\nEven though it‚Äôs choosing among discrete categories, it‚Äôs doing it in a way that‚Äôs smooth and differentiable.\nSome reading material: Arxiv Link"
  }
]