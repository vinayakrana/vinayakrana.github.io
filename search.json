[
  {
    "objectID": "apps.html",
    "href": "apps.html",
    "title": "ScholarBot: AI-powered chatbot designed to assist with academic queries",
    "section": "",
    "text": "ScholarBot: AI-powered chatbot designed to assist with academic queries"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vinayak Rana",
    "section": "",
    "text": "Vinayak Rana is a Master‚Äôs student in Artificial Intelligence at IIT Gandhinagar. He is an active member of the Sustainability Lab, advised by Prof.¬†Nipun Batra. His interests lie in building practical and reliable AI systems, with a focus on spatiotemporal modeling, active learning and natural language processing. Vinayak is passionate about applying machine learning techniques to solve real-world problems and is actively exploring opportunities to contribute to impactful AI research and development. He secured an All India Rank (AIR) of 733 in GATE CS 2024."
  },
  {
    "objectID": "tech_nuggets/posts/dict_key_lookup.html",
    "href": "tech_nuggets/posts/dict_key_lookup.html",
    "title": "Dict Lookup",
    "section": "",
    "text": "In Python, checking whether a key exists in a dictionary is a common operation. But there‚Äôs more than one way to write it:\nif key in my_dict: ...\nif key in my_dict.keys(): ...\nAt first glance, both seem correct and equivalent. But they are not equal in performance or clarity.\nIn this post, we‚Äôll dive into:\n\nThe internal differences between the two\nThe disassembled bytecode\nReal-world benchmarks using timeit\nBest practices and when it actually matters\n\nLet‚Äôs compare the bytecode of two functions, one using in dict and the other using in dict.keys() to see what Python does under the hood.\n\nimport dis\n\ndef direct_lookup(hmap, x):\n    return x in hmap\n\ndef keys_lookup(hmap, x):\n    return x in hmap.keys()\n\ndis.dis(direct_lookup)\nprint(\"-\" * 40)\ndis.dis(keys_lookup)\n\n  4           0 LOAD_FAST                1 (x)\n              2 LOAD_FAST                0 (hmap)\n              4 CONTAINS_OP              0\n              6 RETURN_VALUE\n----------------------------------------\n  7           0 LOAD_FAST                1 (x)\n              2 LOAD_FAST                0 (hmap)\n              4 LOAD_METHOD              0 (keys)\n              6 CALL_METHOD              0\n              8 CONTAINS_OP              0\n             10 RETURN_VALUE\n\n\n\nx in hmap\n\nDirectly uses COMPARE_OP with in on the dictionary\nCalls dict.__contains__, which is optimized and fast\n\n\n\nx in hmap.keys()\n\nCalls .keys() ‚Üí creates a dict_keys view object\nPerforms a membership test on the view\n\nThis adds extra function calls and memory allocation, even though the lookup is still O(1).\nLet‚Äôs use timeit to compare the performance of both lookup styles over 100,000 iterations.\n\nimport timeit\n\nsetup = \"hmap = dict(zip(range(10000), range(10000))); x = 9999\"\nstmt1 = \"x in hmap\"\nstmt2 = \"x in hmap.keys()\"\n\ntime_direct = timeit.timeit(stmt1, setup=setup, number=100_000)\ntime_keys = timeit.timeit(stmt2, setup=setup, number=100_000)\n\nprint(f\"'x in hmap'       : {time_direct:.5f} sec\")\nprint(f\"'x in hmap.keys()': {time_keys:.5f} sec\")\n\n'x in hmap'       : 0.00363 sec\n'x in hmap.keys()': 0.00700 sec\n\n\n\n\nSummary\n\n\n\nStyle\nPerformance\nMemory\n\n\n\n\nx in dict\nFast\nLow\n\n\nx in dict.keys()\nSlower\nHigher\n\n\n\n\n\nWhen to Use .keys()\nUse .keys() only when you need to iterate over or manipulate the entire view object ‚Äî not for simple membership tests.\n\n\n\nWhy It Matters\nWhile the difference is small in absolute terms, understanding Python internals helps write clearer and more efficient code. It also prepares you to debug or optimize larger systems more confidently."
  },
  {
    "objectID": "tech_nuggets/index.html",
    "href": "tech_nuggets/index.html",
    "title": "Tech Nuggets",
    "section": "",
    "text": "Understanding the ‚Äúwhy‚Äù behind system behavior is a core skill in software and ML engineering. These posts demonstrate a habit of going deep into how things work, whether that‚Äôs a faster dictionary lookup, how PyTorch builds a dynamic computation graph, or what causes a memory spike in Docker containers."
  },
  {
    "objectID": "tech_nuggets/index.html#latest-posts",
    "href": "tech_nuggets/index.html#latest-posts",
    "title": "Tech Nuggets",
    "section": "Latest Posts",
    "text": "Latest Posts"
  },
  {
    "objectID": "tech_nuggets/posts/gumbel.html",
    "href": "tech_nuggets/posts/gumbel.html",
    "title": "Gumbel Softmax trick",
    "section": "",
    "text": "Can Neural Networks Learn to Make Hard Choices and Still Be Trained with Backprop?\nImagine your model needs to choose one among several categories say, Red, Green, or Blue. The obvious choice? Use argmax or sample from a categorical distribution. But here‚Äôs the catch: backpropagation doesn‚Äôt work through discrete decisions.\n\n\nSo, are we stuck?\nNot quite. Say hello to the Gumbel-Softmax trick. You can‚Äôt backprop through discrete sampling directly but you can use a continuous relaxation like the Gumbel-Softmax, which approximates categorical sampling in a differentiable way.\n\n\nWhy argmax Kills Your Gradients\nBackpropagation needs continuous functions. But argmax is not one it‚Äôs a discrete, non-differentiable operation. That means if your model makes a hard choice using argmax, the gradient signal hits a wall.\nLet‚Äôs see that in code:\nimport torch\nimport torch.nn.functional as F\n\nlogits = torch.tensor([[2.0, 1.0, 0.1]], requires_grad=True)\nprobs = F.softmax(logits, dim=-1)\nsample = torch.argmax(probs, dim=-1)\n\nloss = sample.float().sum()\nloss.backward()  #  Throws an error\nThe call to .backward() fails because gradients can‚Äôt flow through argmax it‚Äôs not differentiable with respect to logits. The model can‚Äôt learn from this signal.\n\n\nThe Magic Behind Gumbel-Softmax\nWhat if, instead of making a hard discrete decision, your model makes a soft approximation one that‚Äôs almost one-hot but still differentiable?\nThat‚Äôs exactly what the Gumbel-Softmax trick does. It turns the categorical sampling problem into a smooth, trainable operation.\nHere‚Äôs the idea:\n\nimport torch\nimport torch.nn.functional as F\n\ndef sample_gumbel(shape, eps=1e-20):\n    U = torch.rand(shape)\n    return -torch.log(-torch.log(U + eps) + eps)\n\ndef gumbel_softmax(logits, tau=1.0):\n    g = sample_gumbel(logits.shape)\n    return F.softmax((logits + g) / tau, dim=-1)\n\n\nlogits are your raw scores (before softmax).\ng is Gumbel noise, which injects randomness to simulate sampling.\ntau is the temperature a hyperparameter that controls how sharp or soft the final distribution is.\nThe final output is a differentiable approximation of a one-hot vector.\n\nAs œÑ ‚Üí 0, the softmax output becomes almost one-hot, mimicking a discrete choice. As œÑ ‚Üí ‚àû, it becomes uniform, meaning the model explores all choices equally.\nVisual Example: Learn to Blend Colors Let‚Äôs bring this to life with a colorful example.\nImagine your model needs to select one color from a palette Red, Green, or Blue to match a target color like purple üíú. But instead of choosing just one, it learns to blend them softly, using Gumbel-Softmax!\n\nimport torch\nimport torch.nn.functional as F\nimport numpy as np\nimport random\n\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\npalette = torch.tensor([\n    [1.0, 0.0, 0.0],  # Red\n    [0.0, 1.0, 0.0],  # Green\n    [0.0, 0.0, 1.0]   # Blue\n])\n\nlogits = torch.nn.Parameter(torch.randn(1, 3))\n\n# Target color: Purple (blend of Red + Blue)\ntarget = torch.tensor([[0.5, 0.0, 0.5]])\n\nopt = torch.optim.Adam([logits], lr=0.1)\n\nlosses = []\nfor step in range(100):\n    opt.zero_grad()\n    probs = gumbel_softmax(logits, tau=0.5)  # Sample a soft blend\n    color = probs @ palette                  # Weighted sum of RGB\n    loss = F.mse_loss(color, target)\n    losses.append(loss.item())\n    loss.backward()\n    opt.step()\n\n    if step % 10 == 0:\n        print(f\"Step {step}: Loss = {loss.item():.4f}\")\n\nStep 0: Loss = 0.0068\nStep 10: Loss = 0.0021\nStep 20: Loss = 0.1645\nStep 30: Loss = 0.1280\nStep 40: Loss = 0.0734\nStep 50: Loss = 0.1265\nStep 60: Loss = 0.1180\nStep 70: Loss = 0.1632\nStep 80: Loss = 0.0632\nStep 90: Loss = 0.1468\n\n\n\nimport matplotlib.pyplot as plt\nwith torch.no_grad():\n    probs = F.softmax(logits, dim=-1)  # Final softmax\n    blended = probs @ palette          # Final color\n\n    plt.imshow(blended.view(1, 1, 3).numpy())\n    plt.title(f\"Final Color ‚Äî probs={probs.numpy().round(2)}\")\n    plt.axis('off')\n    plt.show()\n\n\n\n\n\n\n\n\n\nEven though we‚Äôre choosing among discrete options (RGB), Gumbel-Softmax lets the model learn differentiably by softly blending probabilities.\nSome reading material: Arxiv Link"
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Publications",
    "section": "",
    "text": "Coming soon‚Ä¶.."
  },
  {
    "objectID": "papers/index.html#section",
    "href": "papers/index.html#section",
    "title": "Publications",
    "section": "",
    "text": "Coming soon‚Ä¶.."
  },
  {
    "objectID": "timeline.html",
    "href": "timeline.html",
    "title": "Timeline",
    "section": "",
    "text": "Will be updated soon‚Ä¶."
  },
  {
    "objectID": "timeline.html#section",
    "href": "timeline.html#section",
    "title": "Timeline",
    "section": "",
    "text": "Will be updated soon‚Ä¶."
  }
]